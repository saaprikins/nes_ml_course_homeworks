{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csMaH5hpuVTz"
   },
   "source": [
    "# Машинное обучение, РЭШ\n",
    "\n",
    "## [Практическое задание 3. Градиентный спуск своими руками](https://www.youtube.com/watch?v=dQw4w9WgXcQ)\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 17.11.2022\n",
    "\n",
    "Дедлайн: 23:59MSK 24.11.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRJFT5yPuVUC"
   },
   "source": [
    "### О задании\n",
    "\n",
    "В данном задании необходимо реализовать обучение линейной регрессии с помощью различных вариантов градиентного спуска.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Задания загружаются на my.nes. Присылать необходимо ноутбук с выполненным заданием. \n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "**Оценка**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-HrP6yvuVUE"
   },
   "source": [
    "## Реализация градиентного спуска\n",
    "\n",
    "Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью:\n",
    "\n",
    "**Задание 1 (1 балл)** Градиентного спуска;\n",
    "\n",
    "**Задание 2.1 (2 балла)** Стохастического градиентного спуска + Batch SGD;\n",
    "\n",
    "**Задание 2.2 (2 балла)** SGD Momentum;\n",
    "\n",
    "**Бонусное задание (2 балл)** Adagrad, RMSProp, Adam;\n",
    "\n",
    "Во всех пунктах необходимо соблюдать следующие условия:\n",
    "\n",
    "* Все вычисления должны быть векторизованы;\n",
    "* Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
    "* В качестве критерия останова необходимо использовать (одновременно):\n",
    "\n",
    "    * проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, задаваемого параметром `tolerance`);\n",
    "    * достижение максимального числа итераций (например, 10000, задаваемого параметром `max_iter`).\n",
    "* Чтобы проследить, что оптимизационный процесс действительно сходится, будем использовать атрибут класса `loss_history` — в нём после вызова метода `fit` должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту);\n",
    "* Инициализировать веса можно случайным образом или нулевым вектором. \n",
    "\n",
    "\n",
    "Ниже приведён шаблон класса, который должен содержать код реализации каждого из методов."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T23:35:20.318574Z",
     "start_time": "2026-02-24T23:35:20.314457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pprint(*args, **kwargs):\n",
    "    print(\">>\", *args, **kwargs)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vzu1xnsCuVUG",
    "ExecuteTime": {
     "end_time": "2026-02-24T23:35:22.922511Z",
     "start_time": "2026-02-24T23:35:22.914337Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class LinearReg(BaseEstimator):\n",
    "    def __init__(self, gd_type='stochastic', \n",
    "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'stochastic'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) - init weights\n",
    "        eta: learning rate\n",
    "        alpha: momentum coefficient\n",
    "        \"\"\"\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.loss_history = None # list of loss function values at each training iteration\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "\n",
    "        # initialize vector of weights\n",
    "        self.w = self.w0\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "\n",
    "            if self.gd_type == 'full':\n",
    "                self.w -= self.eta * self.calc_gradient(X, y)\n",
    "\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "\n",
    "        if self.gd_type == 'full':\n",
    "            return 2 * X.T @ (X @ self.w - y) / y.shape[0]\n",
    "        else:\n",
    "            ...\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jCZy7sRguVUQ",
    "ExecuteTime": {
     "end_time": "2026-02-24T23:35:40.362375Z",
     "start_time": "2026-02-24T23:35:40.357194Z"
    }
   },
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "# test on example from seminar\n",
    "n_features = 2\n",
    "n_objects = 300\n",
    "\n",
    "w_true = np.random.normal(size=(n_features, ))\n",
    "X = np.random.uniform(-5, 5, (n_objects, n_features))\n",
    "X *= (np.arange(n_features) * 2 + 1)[np.newaxis, :]  # for different scales\n",
    "Y = X.dot(w_true) + np.random.normal(0, 1, (n_objects))\n",
    "w_0 = np.random.uniform(-2, 2, (n_features))"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T23:38:13.046160Z",
     "start_time": "2026-02-24T23:38:13.034013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp_class = LinearReg(w0=w_0, gd_type='full')\n",
    "temp_class.w = w_0\n",
    "temp_class.calc_gradient(X=X, y=Y)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -51.39766566, -186.15825013])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAGrUd74uVUX"
   },
   "source": [
    "**Задание 3 (0 баллов)**\n",
    "* Загрузите данные из домашнего задания 2 ([train.csv](https://www.kaggle.com/c/nyc-taxi-trip-duration/data));\n",
    "* Разбейте выборку на обучающую и тестовую в отношении 7:3 с random_seed=0;\n",
    "* Преобразуйте целевую переменную `trip_duration` как $\\hat{y} = \\log{(y + 1)}$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T22:14:20.527222Z",
     "start_time": "2026-02-24T22:14:17.521274Z"
    }
   },
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "# I decided to use already processed data\n",
    "df = pd.read_csv(\"data/final_df_2nd_homework.csv\")\n",
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1458644 entries, 0 to 1458643\n",
      "Data columns (total 26 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   id                  1458644 non-null  str    \n",
      " 1   vendor_id           1458644 non-null  int64  \n",
      " 2   pickup_datetime     1458644 non-null  str    \n",
      " 3   passenger_count     1458644 non-null  int64  \n",
      " 4   pickup_longitude    1458644 non-null  float64\n",
      " 5   pickup_latitude     1458644 non-null  float64\n",
      " 6   dropoff_longitude   1458644 non-null  float64\n",
      " 7   dropoff_latitude    1458644 non-null  float64\n",
      " 8   store_and_fwd_flag  1458644 non-null  int64  \n",
      " 9   log_trip_duration   1458644 non-null  float64\n",
      " 10  weekday             1458644 non-null  str    \n",
      " 11  month               1458644 non-null  int64  \n",
      " 12  hour                1458644 non-null  int64  \n",
      " 13  day_year_number     1458644 non-null  int64  \n",
      " 14  if_anomaly1         1458644 non-null  bool   \n",
      " 15  if_anomaly2         1458644 non-null  bool   \n",
      " 16  haversine           1458644 non-null  float64\n",
      " 17  log_haversine       1458644 non-null  float64\n",
      " 18  high_traffic        1458644 non-null  bool   \n",
      " 19  small_traffic       1458644 non-null  bool   \n",
      " 20  jfk_dropoff         1458644 non-null  bool   \n",
      " 21  jfk_pickup          1458644 non-null  bool   \n",
      " 22  ewr_dropoff         1458644 non-null  bool   \n",
      " 23  ewr_pickup          1458644 non-null  bool   \n",
      " 24  cell_pickup         1458644 non-null  int64  \n",
      " 25  cell_dropoff        1458644 non-null  int64  \n",
      "dtypes: bool(8), float64(7), int64(8), str(3)\n",
      "memory usage: 211.4 MB\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-24T22:14:21.950165Z",
     "start_time": "2026-02-24T22:14:20.533397Z"
    }
   },
   "cell_type": "code",
   "source": "train_df, test_df = train_test_split(df, test_size=0.3, random_state=0)",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaX55pBGuVUd"
   },
   "source": "**Задание 4 (3 балла)**. Обучите и провалидируйте модели на данных из предыдущего пункта, сравните качество между методами по метрикам MSE и $R^2$. Исследуйте влияние параметров `max_iter` и `eta` на процесс оптимизации. Согласуется ли оно с вашими ожиданиями?"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pMNYu96euVUe",
    "ExecuteTime": {
     "end_time": "2026-02-24T22:18:23.667246Z",
     "start_time": "2026-02-24T22:18:23.661864Z"
    }
   },
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "lin_ref = LinearReg(max_iter=10, gd_type='full')"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNJSqm8duVUj"
   },
   "source": [
    "**Задание 5 (6 балла)**. Постройте графики (на одной и той же картинке) зависимости величины функции потерь от номера итерации для всех реализованных видов стохастического градиентного спусков. Сделайте выводы о скорости сходимости различных модификаций градиентного спуска.\n",
    "\n",
    "Не забывайте о том, что должны получиться *красивые* графики!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gUTUbdtuVUk"
   },
   "outputs": [],
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1NRgPkeuVUr"
   },
   "source": "**Задание 6 (бонус) (0.01 балла)**.  Вставьте картинку с вашим любимым мемом в этот Jupyter Notebook"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ooLLNAAbw6u9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
